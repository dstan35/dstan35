<!DOCTYPE html>
<html lang="en"><head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta charset="utf-8">
  <title>Computer Vision Course Project
  | ECE, Virginia Tech | Fall 2020: ECE 4554/5554</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta name="description" content="">
  <meta name="author" content="">

<!-- Le styles -->
  <link href="css/bootstrap.css" rel="stylesheet">
<style>
body {
padding-top: 60px; /* 60px to make the container go all the way to the bottom of the topbar */
}
.vis {
color: #3366CC;
}
.data {
color: #FF9900;
}
</style>

<link href="css/bootstrap-responsive.min.css" rel="stylesheet">

<!-- HTML5 shim, for IE6-8 support of HTML5 elements --><!--[if lt IE 9]>
<script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
<![endif]-->
</head>

<body>
<div class="container">
<div class="page-header">

<!-- Title and Name -->
<h1>Image Classification of Pedestrians</h1>
<span style="font-size: 20px; line-height: 1.5em;"><strong>Group 23: David Stanley/Jhonie Geffa</strong></span><br>
<span style="font-size: 18px; line-height: 1.5em;">Fall 2020 ECE 4554/5554 Computer Vision: Course Project</span><br>
<span style="font-size: 18px; line-height: 1.5em;">Virginia Tech</span>
<hr>

<!-- Proposal -->
<!--
<h2>Proposal Elements</h2>
<h3>Problem Statement</h3>
The goal of this project is to create a system that will identify pedestrians in pictures and
visualize an area around the pedestrians not to be entered by autonomous vehicles.
This project is inspired by the recent incidents involving autonomous vehicles and pedestrians.
<br>
<strong>Input:</strong>
The input to this project will be a still image(s) that may or may not contain
a pedestrian. The project will use a large dataset of these images to train the algorithm.
<br>
<strong>Output:</strong>
The output of this project will be a still image(s) that will contain a box around all pedestrians.
<h3>Approach</h3>
Pedestrian detection is an actively researched area in computer vision with multiple different types of approaches.
Existing approaches include holistic detection, part-based detection, patch-based detection, motion-based detection, and detection using multiple cameras.
For this project we will approach this problem using holistic detection.
<br><br>
Holistic detection focuses on training detectors to search for pedestrians in the image.
The detector would highlight features in the local searching window that meet the criteria of the object.
Such criteria includes a set of edge templates of pedestrians to compare against. Other systems include local features like histogram of oriented gradients.
The problem with this method is the adverse effect of background clutter has on performance.
For the scope of this project the image dataset used will limit the number of environment distraction to help with performance.
This will come with the drawback that our implementation will not have widespread use.
<h3>Experiments and Results</h3>
This project will use a large existing dataset from UPenn, shown <a href="https://www.cis.upenn.edu/~jshi/ped_html/">here</a>
for both training and testing data. The training data will be used to train the model
to identify pedestrians and draw an image box around them. After training has been completed,
the remaining images will have the locations of their image boxes recorded and validated against pre-determined coordinates
from bounding in OpenCV or manually identifying bounds. This experiment will be considered successful if each pedestrian is identified
and the output image box location is centered within a 25% error bound from the center of the pedestrian.
The only code borrowed to complete this project will be from OpenCV to use filtering methods and for image bound comparison.
-->

<!-- Final Report -->
<h2>Final Report</h2>
<h3>Abstract</h3>
The goal of this project was to analyze and explore existing methods of identifying pedestrians in pictures to
visualize an area around the pedestrians not to be entered by autonomous vehicles.
This project was inspired by the recent incidents involving autonomous vehicles and pedestrians.
The approach for this project was to use both holistic detection and part-based detection to find pedestrians in each image.
While neither method was optimal, holistic detection was much more effective at identifying pedestrians.
<h3>Teaser Figure</h3>
<!-- figure -->
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="teaserPic.png">
<br>
Figure 1: Example of correctly identified pedestrians from UPenn research.
</div>
<h3>Introduction</h3>
The motivation for this project is the rapid development of autonomous vehicles. These vehicles rely on pedestrian detection to avoid accidents. The goal of this project was to learn more about how pedestrians are identified by machines.
Background research identified that existing approaches include holistic detection, part-based detection, patch-based detection, motion-based detection, and detection using multiple cameras.
<br>
For this project, two different types of pedestrian detection systems were implemented: holistic detection and part-based detection.
In holistic detection, the algorithm searches for the whole body of the person to decide if it shows up in the image. In part-based detection, a person’s body is subdivided into 2 or more parts and those parts are used to identify a person in an image.
For this project, the person model was subdivided into a top and lower half. If both halves were found and were close to each other, the algorithm would detect that person.
<br>
The use cases of this project are to mimic existing research into pedestrian detection. This is a fascinating problem
that has a lot of real world impact as autonomous vehicles come closer and closer to full commercialization.
<h3>Approach</h3>
Holistic detection focuses on training detectors to search for pedestrians in the image.
The detector would highlight features in the local searching window that meet the criteria of the object.
Such criteria includes a set of edge templates of pedestrians to compare against. Other systems include local features like histogram of oriented gradients.
The problem with this method is the adverse effect of background clutter has on performance.
For the scope of this project the image dataset used will limit the number of environment distraction to help with performance.
This will come with the drawback that our implementation will not have widespread use.
<h3>Experiments and Results</h3>
This project used a large existing dataset from UPenn, shown <a href="https://www.cis.upenn.edu/~jshi/ped_html/">here</a>
for both training and testing data. The training data was used to train the model
to identify pedestrians and draw an image box around them. After training was completed,
the remaining images had the locations of their image boxes recorded and validated against pre-determined coordinates
from bounding in OpenCV.
<br>
This experiment will be considered successful if each pedestrian is identified
and the output image box location is centered within a 25% error bound from the center of the pedestrian.
The only code borrowed to complete this project was from OpenCV to use filtering methods and for image bound comparison.
<h3>Qualitative Results</h3>
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="holisticSucc1.png">
<br>
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="holSucc2.png">
<br>
Figures 2/3: Examples of correctly identified pedestrians using holistic detection.
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="partSucc1.png">
<br>
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="partSucc2.png">
<br>
Figures 4/5: Examples of correctly identified pedestrians using part-based detection. Figure 5 shows an example
of forward-facing detection working best.
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="holFalse1.png">
<br>
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="holFalse2.png">
<br>
Figures 6/7: Examples of false positives using holistic detection (trash can).
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="partFalse1.png">
<br>
Figure 8: Example of false positive using part-based detection (tree on left of image).
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="holMiss1.png">
<br>
Figure 9: Example of false negative using holistic detection.
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="partMiss1.png">
<br>
Figure 10: Example of false negative using part-based detection.
<div style="text-align: left;">
<img style="height: 200px;" alt="" src="partMissingLower.png">
<br>
Figure 11: Example of part-based detection missing lower part.
<div style="text-align: left;">
<img style="height: 300px;" alt="" src="barChart.png">
<br>
Figure 12: Bar graph showing results across dataset.
<h3>Conclusion and Future Work</h3>
This report has described the approach and results of two algorithms used to detect pedestrians: part-based detection and holistic detection.
Overall, this paper found why holistic detection is the preferred method of pedestrian detection
in computer vision today. The results obtained show that while holistic detection is far from
perfect, it performs much more reliably than it's part-based counterpart.
<br>
One of the most important aspects of detection that needs to be studied is performance variance
at different angles. Both of these algorithms performed much better when a front-facing pedestrian
was shown, while both performed poorly when viewing pedestrians from the side. Even during the
research phase of the project, it was clear that most existing classifiers performed better on front facing
pedestrians.
<h3>References</h3>
<!-- Final Report -->
<!--
<h2>Final Report</h2>
-->
  <hr>
  <footer>
  <p>© Group 23: David Stanley/Jhonie Geffa</p>
  </footer>
</div>
</div>

<br><br>

</body></html>
